{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZkbyZxZqbCMcNQ06hpFzh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/instquality/\")\n","\n","import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/instquality/\")\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1H81BJGDEmC","executionInfo":{"status":"ok","timestamp":1762262837203,"user_tz":0,"elapsed":19541,"user":{"displayName":"Jan Darecki","userId":"10106417627822015827"}},"outputId":"140c60e9-c151-4c65-8341-13ab6ea027c4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2lYc6FbcCjPf","executionInfo":{"status":"ok","timestamp":1762262953263,"user_tz":0,"elapsed":1099,"user":{"displayName":"Jan Darecki","userId":"10106417627822015827"}}},"outputs":[],"source":["import os, time\n","import numpy as np\n","import pandas as pd\n","from scipy.stats import norm\n","from sklearn.linear_model import Lasso, Ridge, ElasticNet\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from IPython.display import display\n","from joblib import Parallel, delayed\n","\n","def _yearwise_splits(years, min_train_years=8, stride=2):\n","    ys = np.asarray(years)\n","    uniq = np.sort(np.unique(ys))\n","    for k in range(min_train_years, len(uniq), stride):\n","        train = np.where(np.isin(ys, uniq[:k]))[0]\n","        val = np.where(ys == uniq[k])[0]\n","        yield train, val\n","\n","def _rmse_for_param(param, X, y, years, model_type='lasso', l1_ratio=0.5, min_train_years=8, stride=2):\n","    rmse = []\n","    if model_type == 'lasso':\n","        model = Lasso(alpha=param, max_iter=10000, warm_start=True)\n","    elif model_type == 'ridge':\n","        model = Ridge(alpha=param)\n","    elif model_type == 'elastic':\n","        model = ElasticNet(alpha=param, l1_ratio=l1_ratio, max_iter=10000)\n","    else:\n","        raise ValueError(f\"Unknown model_type: {model_type}\")\n","    for tr, va in _yearwise_splits(years, min_train_years, stride):\n","        model.fit(X.iloc[tr], y.iloc[tr])\n","        pred = model.predict(X.iloc[va])\n","        rmse.append(np.sqrt(mean_squared_error(y.iloc[va], pred)))\n","    return param, float(np.mean(rmse)) if rmse else np.inf\n","\n","def choose_param_expanding(X, y, years, model_type='lasso', l1_ratio=0.5, params_coarse=None, params_fine=12, min_train_years=8, stride=2, n_jobs=-1):\n","    if params_coarse is None:\n","        params_coarse = np.logspace(0, 5, 20) if model_type == 'ridge' else np.logspace(-4, 1, 15)\n","    coarse = Parallel(n_jobs=n_jobs)(\n","        delayed(_rmse_for_param)(p, X, y, years, model_type, l1_ratio, min_train_years, stride)\n","        for p in sorted(params_coarse, reverse=True)\n","    )\n","    p0 = min(coarse, key=lambda t: t[1])[0]\n","    low, high = p0/10, p0*10\n","    fine_grid = np.logspace(np.log10(low), np.log10(high), params_fine)\n","    fine = Parallel(n_jobs=n_jobs)(\n","        delayed(_rmse_for_param)(p, X, y, years, model_type, l1_ratio, min_train_years, stride)\n","        for p in sorted(fine_grid, reverse=True)\n","    )\n","    return min(fine, key=lambda t: t[1])[0]\n","\n","def _dm_test(e0, e1):\n","    d = e0**2 - e1**2\n","    T = len(d)\n","    v = np.var(d, ddof=1)\n","    if T < 2 or v == 0 or np.isnan(v):\n","        return np.nan, np.nan\n","    stat = d.mean() / np.sqrt(v / T)\n","    pval = 2 * (1 - norm.cdf(abs(stat)))\n","    return stat, pval\n","\n","def decompose_r2(y_true, y_pred, X, coefs, feature_names):\n","    y_true = np.asarray(y_true).flatten()\n","    y_pred = np.asarray(y_pred).flatten()\n","    X = np.asarray(X)\n","    coefs = np.asarray(coefs).flatten()\n","    y_centered = y_true - y_true.mean()\n","    X_centered = X - X.mean(axis=0)\n","    contributions = []\n","    for j in range(X.shape[1]):\n","        cov_j = np.dot(X_centered[:, j], y_centered) / len(y_centered)\n","        contrib = coefs[j] * cov_j\n","        contributions.append(contrib)\n","    contributions = np.array(contributions)\n","    total_contrib = contributions.sum()\n","    r2 = r2_score(y_true, y_pred)\n","    if total_contrib != 0:\n","        normalized_contrib = (contributions / total_contrib) * r2\n","    else:\n","        normalized_contrib = np.zeros_like(contributions)\n","    decomp_df = pd.DataFrame({\n","        'variable': feature_names,\n","        'coefficient': coefs,\n","        'contribution': contributions,\n","        'r2_contribution': normalized_contrib,\n","        'r2_contribution_pct': normalized_contrib * 100\n","    })\n","    decomp_df = decomp_df.reindex(decomp_df['r2_contribution'].abs().sort_values(ascending=False).index)\n","    return decomp_df\n","\n","def run_unified_regularized_regression(\n","    name_prefix=\"base\",\n","    data_path=\"saved/df.dat\",\n","    macro_cols=None,\n","    iq_cols=None,\n","    y_name=\"tgt_spread_lag\",\n","    spread_col=\"tgt_spread\",\n","    year_col=\"year\",\n","    split_year=2015,\n","    model_types=['lasso', 'ridge', 'elastic'],\n","    agnostic=False,\n","    param_factors=[0.5, 1.0, 2.0],\n","    l1_ratio=0.5,\n","    use_expanding_cv=True,\n","    min_train_years=8,\n","    cv_stride=2,\n","    r2_benchmark=None,\n","    rmse_benchmark=None,\n","    save_results=True,\n","    output_dir=\"specs\",\n","    n_jobs=-1\n","):\n","    print(f\"\\n{'='*80}\")\n","    print(f\"UNIFIED REGULARIZED REGRESSION: {name_prefix.upper()}\")\n","    print(f\"Specification: {'Agnostic (β unrestricted)' if agnostic else 'β=1 (mean reversion)'}\")\n","    print(f\"Models: {', '.join([m.upper() for m in model_types])}\")\n","    print(f\"{'='*80}\\n\")\n","    start_time = time.time()\n","\n","    df = pd.read_pickle(data_path)\n","    df[year_col] = df[year_col].astype(int)\n","\n","    if macro_cols is None:\n","        macro_cols = []\n","    if iq_cols is None:\n","        iq_cols = []\n","\n","    train_data = df[df[year_col] <= split_year].copy()\n","    test_data = df[df[year_col] > split_year].copy()\n","\n","    print(f\"Train: {train_data[year_col].min()}-{train_data[year_col].max()} ({len(train_data)} obs)\")\n","    print(f\"Test:  {test_data[year_col].min()}-{test_data[year_col].max()} ({len(test_data)} obs)\\n\")\n","\n","    feature_cols = macro_cols + iq_cols\n","    if spread_col in feature_cols and not agnostic:\n","        feature_cols = [c for c in feature_cols if c != spread_col]\n","\n","    X_train_raw = train_data[feature_cols].copy()\n","    X_test_raw = test_data[feature_cols].copy()\n","    y_train = train_data[y_name].copy()\n","    y_test = test_data[y_name].copy()\n","    years_train = train_data[year_col].values\n","\n","    if not agnostic:\n","        if spread_col not in train_data.columns:\n","            raise ValueError(f\"β=1 specification requires '{spread_col}' column\")\n","        spread_train = train_data[spread_col].copy()\n","        spread_test = test_data[spread_col].copy()\n","        mask_train = spread_train.notna() & y_train.notna()\n","        mask_test = spread_test.notna() & y_test.notna()\n","        X_train_raw = X_train_raw.loc[mask_train]\n","        X_test_raw = X_test_raw.loc[mask_test]\n","        y_train = y_train.loc[mask_train]\n","        y_test = y_test.loc[mask_test]\n","        spread_train = spread_train.loc[mask_train]\n","        spread_test = spread_test.loc[mask_test]\n","        years_train = years_train[mask_train.values]\n","        y_train_adj = y_train - spread_train\n","        y_test_adj = y_test - spread_test\n","        print(f\"β=1 specification: predicting (y_t+1 - spread_t)\")\n","        print(f\"After removing NaN: {len(y_train_adj)} train, {len(y_test_adj)} test obs\\n\")\n","    else:\n","        y_train_adj = y_train\n","        y_test_adj = y_test\n","        spread_train = None\n","        spread_test = None\n","\n","    scaler = StandardScaler()\n","    imputer = SimpleImputer(strategy='median')\n","    X_train_imp = imputer.fit_transform(X_train_raw)\n","    X_test_imp = imputer.transform(X_test_raw)\n","    X_train = pd.DataFrame(scaler.fit_transform(X_train_imp), index=X_train_raw.index, columns=X_train_raw.columns)\n","    X_test = pd.DataFrame(scaler.transform(X_test_imp), index=X_test_raw.index, columns=X_test_raw.columns)\n","    feature_names = list(X_train.columns)\n","    print(f\"Features: {len(feature_names)}\\n\")\n","\n","    all_results = {}\n","\n","    for model_type in model_types:\n","        print(f\"\\n{'-'*80}\")\n","        print(f\"RUNNING {model_type.upper()}\")\n","        print(f\"{'-'*80}\\n\")\n","\n","        if use_expanding_cv:\n","            print(\"Selecting optimal parameter via expanding window CV...\")\n","            optimal_param = choose_param_expanding(X_train, y_train_adj, years_train, model_type=model_type, l1_ratio=l1_ratio, min_train_years=min_train_years, stride=cv_stride, n_jobs=n_jobs)\n","        else:\n","            params = np.logspace(0, 5, 30) if model_type == 'ridge' else np.logspace(-4, 1, 30)\n","            best_score = -np.inf\n","            optimal_param = params[0]\n","            for p in params:\n","                if model_type == 'lasso':\n","                    m = Lasso(alpha=p, max_iter=10000)\n","                elif model_type == 'ridge':\n","                    m = Ridge(alpha=p)\n","                else:\n","                    m = ElasticNet(alpha=p, l1_ratio=l1_ratio, max_iter=10000)\n","                m.fit(X_train, y_train_adj)\n","                score = m.score(X_train, y_train_adj)\n","                if score > best_score:\n","                    best_score = score\n","                    optimal_param = p\n","\n","        print(f\"Optimal parameter: {optimal_param:.6f}\\n\")\n","\n","        results_rows = []\n","        models = {}\n","\n","        for factor in param_factors:\n","            param = optimal_param * factor\n","            if model_type == 'lasso':\n","                model = Lasso(alpha=param, max_iter=10000)\n","            elif model_type == 'ridge':\n","                model = Ridge(alpha=param)\n","            else:\n","                model = ElasticNet(alpha=param, l1_ratio=l1_ratio, max_iter=10000)\n","            model.fit(X_train, y_train_adj)\n","            y_pred_test_adj = model.predict(X_test)\n","            y_pred_train_adj = model.predict(X_train)\n","            if not agnostic:\n","                y_pred_test = spread_test + y_pred_test_adj\n","                y_pred_train = spread_train + y_pred_train_adj\n","            else:\n","                y_pred_test = y_pred_test_adj\n","                y_pred_train = y_pred_train_adj\n","            r2_train = r2_score(y_train, y_pred_train)\n","            r2_test = r2_score(y_test, y_pred_test)\n","            rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","            active_vars = np.sum(model.coef_ != 0)\n","            if not agnostic:\n","                e_benchmark = y_test - spread_test\n","                e_model = y_test - y_pred_test\n","                dm_stat, dm_p = _dm_test(e_benchmark, e_model)\n","            else:\n","                dm_stat, dm_p = np.nan, np.nan\n","            results_rows.append({'factor': factor, 'param': param, 'R²_train': r2_train, 'R²_test': r2_test, 'RMSE_test': rmse_test, 'Active_vars': active_vars, 'DM_stat': dm_stat, 'DM_p': dm_p})\n","            models[factor] = (model, y_pred_test)\n","\n","        results_df = pd.DataFrame(results_rows)\n","        display(results_df)\n","\n","        best_idx = results_df['R²_test'].idxmax()\n","        best_row = results_df.iloc[best_idx]\n","        best_model, best_pred = models[best_row['factor']]\n","\n","        print(f\"\\nBest {model_type.upper()}:\")\n","        print(f\"  Parameter: {best_row['param']:.6f}\")\n","        print(f\"  R² (test): {best_row['R²_test']:.4f}\")\n","        print(f\"  RMSE (test): {best_row['RMSE_test']:.4f}\")\n","        print(f\"  Active vars: {int(best_row['Active_vars'])}\")\n","        if r2_benchmark is not None:\n","            print(f\"  ΔR² vs benchmark: {(best_row['R²_test'] - r2_benchmark)*100:+.2f} p.p.\")\n","        if rmse_benchmark is not None:\n","            print(f\"  ΔRMSE vs benchmark: {(best_row['RMSE_test'] - rmse_benchmark):+.4f}\")\n","        if not agnostic:\n","            print(f\"  DM test: stat={best_row['DM_stat']:.2f}, p={best_row['DM_p']:.3f}\")\n","\n","        print(f\"\\n{'='*80}\")\n","        print(f\"VARIABLE IMPORTANCE DECOMPOSITION ({model_type.upper()})\")\n","        print(f\"{'='*80}\\n\")\n","\n","        decomp_df = decompose_r2(y_test, best_pred, X_test, best_model.coef_, feature_names)\n","        top_n = min(20, len(decomp_df))\n","        print(f\"Top {top_n} contributors to R²:\\n\")\n","        display(decomp_df.head(top_n)[['variable', 'coefficient', 'r2_contribution', 'r2_contribution_pct']])\n","\n","        total_r2_explained = decomp_df['r2_contribution'].sum()\n","        print(f\"\\nTotal R² explained: {total_r2_explained:.4f}\")\n","        print(f\"Sum of absolute contributions: {decomp_df['r2_contribution'].abs().sum():.4f}\")\n","\n","        if save_results:\n","            os.makedirs(output_dir, exist_ok=True)\n","            suffix = f\"{'_agn' if agnostic else ''}\"\n","            results_df.to_pickle(f\"{output_dir}/{model_type}_{name_prefix}{suffix}_results.dat\")\n","            decomp_df.to_pickle(f\"{output_dir}/{model_type}_{name_prefix}{suffix}_decomp.dat\")\n","            pd.Series(best_model.coef_, index=feature_names).to_pickle(f\"{output_dir}/{model_type}_{name_prefix}{suffix}_coefs.dat\")\n","\n","        all_results[model_type] = {'results_df': results_df, 'best_model': best_model, 'best_row': best_row, 'decomposition': decomp_df, 'predictions': best_pred}\n","\n","    elapsed = time.time() - start_time\n","    print(f\"\\n{'='*80}\")\n","    print(f\"COMPLETED IN {elapsed:.1f}s\")\n","    print(f\"{'='*80}\\n\")\n","    return all_results"]},{"cell_type":"code","source":["# Define your columns\n","df = pd.read_pickle(\"saved/df.dat\")\n","id_cols = [\"country\",\"year\",\"iso_code_1\",\"iso_code_2\",\"region\"]\n","exclude = id_cols + [c for c in df.columns if c.startswith(\"tgt_\")]\n","macro_cols = [c for c in df.columns if c.startswith(\"wb_\") and not c.startswith(\"wb_iq_\") and c not in exclude]\n","iq_cols = [c for c in df.columns if (c.startswith(\"wb_iq_\") or (not c.startswith(\"wb_\") and c not in exclude))]\n","\n","# Run specification\n","results = run_unified_regularized_regression(\n","    name_prefix=\"base\",\n","    data_path=\"saved/df.dat\",\n","    macro_cols=macro_cols,\n","    iq_cols=iq_cols,\n","    y_name='tgt_spread',\n","    spread_col=\"tgt_spread\", # only used for next-year spread prediction, especially in non-agnostic version\n","    year_col=\"year\",\n","    split_year=2015,\n","    model_types=['lasso', 'ridge', 'elastic'],\n","    agnostic=True,\n","    param_factors=np.logspace(-10, 10, 25),\n","    l1_ratio=0.5,\n","    use_expanding_cv=True,\n","    min_train_years=8,\n","    cv_stride=2,\n","    r2_benchmark=None,\n","    rmse_benchmark=None,\n","    save_results=True,\n","    output_dir=\"specs\",\n","    n_jobs=-1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHz0MGIWCoqX","outputId":"10e1ba3a-a700-47f3-8ade-08ecafd67b75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","UNIFIED REGULARIZED REGRESSION: BASE\n","Specification: Agnostic (β unrestricted)\n","Models: LASSO, RIDGE, ELASTIC\n","================================================================================\n","\n","Train: 1960-2015 (1652 obs)\n","Test:  2016-2024 (541 obs)\n","\n","Features: 245\n","\n","\n","--------------------------------------------------------------------------------\n","RUNNING LASSO\n","--------------------------------------------------------------------------------\n","\n","Selecting optimal parameter via expanding window CV...\n"]}]}]}